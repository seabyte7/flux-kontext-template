import { fal } from "@fal-ai/client";
import { r2Storage } from "@/lib/services/r2-storage";
import { fluxLogger } from "@/lib/logger";

// é…ç½®FALå®¢æˆ·ç«¯
if (process.env.FAL_KEY) {
  fal.config({
    credentials: process.env.FAL_KEY
  });
  fluxLogger.info({ keyPrefix: process.env.FAL_KEY.substring(0, 10) }, 'FAL client configured');

  // ğŸ” éªŒè¯FALå®¢æˆ·ç«¯é…ç½®
  try {
    const keyLength = process.env.FAL_KEY.length;
    const keyPrefix = process.env.FAL_KEY.substring(0, 4);
    fluxLogger.debug({ keyLength, keyPrefix, isValidLength: keyLength > 20 }, 'FAL key validation');
  } catch (keyError) {
    fluxLogger.error({ err: keyError }, 'FAL key validation error');
  }
} else {
  fluxLogger.error('FAL_KEY environment variable not found');
}

// å®šä¹‰APIç«¯ç‚¹å¸¸é‡ - ğŸ”§ æ ¹æ®FAL APIå®˜æ–¹æ–‡æ¡£å®Œå…¨ä¿®å¤ç«¯ç‚¹
export const FLUX_ENDPOINTS = {
  // ğŸ”§ Kontext å›¾åƒç¼–è¾‘ç«¯ç‚¹ï¼ˆimage-to-imageï¼‰- æ ¹æ®å®˜æ–¹æ–‡æ¡£ä¿®å¤
  KONTEXT_PRO: "fal-ai/flux-pro/kontext",
  KONTEXT_MAX: "fal-ai/flux-pro/kontext/max", 
  
  // ğŸ”§ Kontext å¤šå›¾åƒç¼–è¾‘ç«¯ç‚¹ - æ ¹æ®å®˜æ–¹æ–‡æ¡£ä¿®å¤
  KONTEXT_MAX_MULTI: "fal-ai/flux-pro/kontext/max/multi",
  KONTEXT_PRO_MULTI: "fal-ai/flux-pro/kontext/multi",
  
  // ğŸ”§ æ ‡å‡†FLUXæ–‡ç”Ÿå›¾ç«¯ç‚¹ - æ ¹æ®å®˜æ–¹æ–‡æ¡£ä¿®å¤
  FLUX_PRO_TEXT_TO_IMAGE: "fal-ai/flux-pro",
  FLUX_MAX_TEXT_TO_IMAGE: "fal-ai/flux-pro/v1.1", // FLUX1.1 [pro]
  
  // ğŸ”§ æ ‡å‡†FLUXç«¯ç‚¹ - æ ¹æ®å®˜æ–¹æ–‡æ¡£ä¿®å¤
  FLUX_SCHNELL: "fal-ai/flux/schnell",
  FLUX_DEV: "fal-ai/flux/dev",
  FLUX_GENERAL: "fal-ai/flux-general", // é€šç”¨FLUXç«¯ç‚¹ï¼Œæ”¯æŒLoRA
  FLUX_REALISM: "fal-ai/flux-lora", // ä½¿ç”¨LoRAå®ç°çœŸå®æ„Ÿ
  FLUX_ANIME: "fal-ai/flux-lora" // ä½¿ç”¨LoRAå®ç°åŠ¨æ¼«é£æ ¼
} as const;

// å®šä¹‰ç±»å‹æ¥å£
export interface FluxKontextBaseInput {
  prompt: string;
  seed?: number;
  guidance_scale?: number;
  sync_mode?: boolean;
  num_images?: number;
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  output_format?: "jpeg" | "png";
}

export interface FluxKontextImageEditInput extends FluxKontextBaseInput {
  image_url: string;
  aspect_ratio?: "21:9" | "16:9" | "4:3" | "3:2" | "1:1" | "2:3" | "3:4" | "9:16" | "9:21";
}

export interface FluxKontextMultiImageInput extends FluxKontextBaseInput {
  image_urls: string[];
  aspect_ratio?: "21:9" | "16:9" | "4:3" | "3:2" | "1:1" | "2:3" | "3:4" | "9:16" | "9:21";
}

export interface FluxKontextTextToImageInput extends FluxKontextBaseInput {
  aspect_ratio?: "21:9" | "16:9" | "4:3" | "3:2" | "1:1" | "2:3" | "3:4" | "9:16" | "9:21";
}

export interface FluxKontextImage {
  url: string;
  width?: number;
  height?: number;
  content_type?: string;
}

export interface FluxKontextResult {
  images: FluxKontextImage[];
  timings?: any;
  seed?: number;
  has_nsfw_concepts?: boolean[];
  prompt?: string;
}

// Flux Kontext APIæœåŠ¡ç±»
export class FluxKontextService {
  
  /**
   * Kontext [pro] - å›¾åƒç¼–è¾‘
   * å¿«é€Ÿè¿­ä»£ç¼–è¾‘ï¼Œä¿æŒè§’è‰²ä¸€è‡´æ€§
   */
  static async editImagePro(input: FluxKontextImageEditInput): Promise<FluxKontextResult> {
    try {
      // ğŸ”§ æ ¹æ®APIæ–‡æ¡£ï¼Œç§»é™¤ä¸æ”¯æŒçš„aspect_ratioå‚æ•°
      const kontextInput = {
        prompt: input.prompt,
        image_url: input.image_url,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format
        // âŒ ç§»é™¤ aspect_ratio - Kontext APIä¸æ”¯æŒæ­¤å‚æ•°
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.KONTEXT_PRO, prompt: input.prompt?.substring(0, 100) }, 'Starting editImagePro');
      
      const result = await fal.subscribe(FLUX_ENDPOINTS.KONTEXT_PRO, {
        input: kontextInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status, position: (update as any).queue_position }, 'Queue update');
        },
      });

      fluxLogger.debug({ hasData: !!result.data, imagesCount: result.data?.images?.length || 0 }, 'FAL subscribe result');

      if (!result.data) {
        fluxLogger.error('FAL subscribe returned no data');
        throw new Error('FAL API returned no data - this may indicate a service issue or invalid request');
      }

      if (!result.data.images) {
        fluxLogger.error({ dataKeys: Object.keys(result.data) }, 'FAL subscribe data has no images');

        const possibleFields = ['image', 'output', 'result'];
        for (const field of possibleFields) {
          if ((result.data as any)[field]) {
            fluxLogger.debug({ field }, 'Found potential images in alternate field');
            if (Array.isArray((result.data as any)[field])) {
              (result.data as any).images = (result.data as any)[field];
              break;
            } else if (typeof (result.data as any)[field] === 'string') {
              (result.data as any).images = [{ url: (result.data as any)[field] }];
              break;
            }
          }
        }

        if (!result.data.images) {
          throw new Error('FAL API returned data without images field');
        }
      }

      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error, prompt: input.prompt?.substring(0, 100) }, 'Flux Kontext Pro editing error');
      throw error;
    }
  }

  /**
   * Kontext [max] - å›¾åƒç¼–è¾‘
   * æœ€é«˜æ€§èƒ½ï¼Œæ”¹è¿›çš„æç¤ºéµå¾ªå’Œæ’ç‰ˆç”Ÿæˆ
   */
  static async editImageMax(input: FluxKontextImageEditInput): Promise<FluxKontextResult> {
    try {
      const kontextInput = {
        prompt: input.prompt,
        image_url: input.image_url,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.KONTEXT_MAX, prompt: input.prompt?.substring(0, 100) }, 'Starting editImageMax');

      const result = await fal.subscribe(FLUX_ENDPOINTS.KONTEXT_MAX, {
        input: kontextInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status }, 'Queue update');
        },
      });
      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error, prompt: input.prompt?.substring(0, 100) }, 'Flux Kontext Max editing error');
      throw error;
    }
  }

  /**
   * Kontext [max] - å¤šå›¾åƒç¼–è¾‘ï¼ˆå®éªŒæ€§ï¼‰
   * å¤„ç†å¤šä¸ªå›¾åƒçš„ç¼–è¾‘åŠŸèƒ½
   */
  static async editMultiImageMax(input: FluxKontextMultiImageInput): Promise<FluxKontextResult> {
    try {
      const kontextInput = {
        prompt: input.prompt,
        image_urls: input.image_urls,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.KONTEXT_MAX_MULTI, prompt: input.prompt?.substring(0, 100), imageCount: input.image_urls?.length }, 'Starting editMultiImageMax');

      const result = await fal.subscribe(FLUX_ENDPOINTS.KONTEXT_MAX_MULTI, {
        input: kontextInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status }, 'Queue update');
        },
      });
      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error, prompt: input.prompt?.substring(0, 100) }, 'Flux Kontext Max multi-image editing error');
      throw error;
    }
  }

  /**
   * Kontext [max] - æ–‡æœ¬ç”Ÿæˆå›¾åƒ
   * æœ€é«˜æ€§èƒ½çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ
   */
  static async textToImageMax(input: FluxKontextTextToImageInput): Promise<FluxKontextResult> {
    try {
      // ğŸ”§ è½¬æ¢å‚æ•°æ ¼å¼ï¼šæ ‡å‡†FLUXç«¯ç‚¹ä½¿ç”¨image_sizeè€Œä¸æ˜¯aspect_ratio
      const fluxInput = {
        prompt: input.prompt,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        sync_mode: input.sync_mode,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format,
        // ğŸ”§ å°†aspect_ratioè½¬æ¢ä¸ºimage_sizeæ ¼å¼
        image_size: this.convertAspectRatioToImageSize(input.aspect_ratio)
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.FLUX_MAX_TEXT_TO_IMAGE, prompt: input.prompt?.substring(0, 100) }, 'Starting textToImageMax');

      const result = await fal.subscribe(FLUX_ENDPOINTS.FLUX_MAX_TEXT_TO_IMAGE, {
        input: fluxInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status, position: (update as any).queue_position }, 'Queue update');
        },
      });

      fluxLogger.debug({ hasData: !!result.data, imagesCount: result.data?.images?.length || 0 }, 'FAL subscribe result');

      if (!result.data) {
        fluxLogger.error('FAL subscribe returned no data');
        throw new Error('FAL API returned no data - this may indicate a service issue or invalid request');
      }

      // ğŸ” æ£€æŸ¥dataç»“æ„
      if (!result.data.images) {
        fluxLogger.error({ dataKeys: Object.keys(result.data) }, 'FAL subscribe data has no images');

        // ğŸ” å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„å›¾ç‰‡å­—æ®µ
        const possibleFields = ['image', 'output', 'result'];
        for (const field of possibleFields) {
          if ((result.data as any)[field]) {
            fluxLogger.debug({ field }, 'Found potential images in alternate field');
            if (Array.isArray((result.data as any)[field])) {
              (result.data as any).images = (result.data as any)[field];
              break;
            } else if (typeof (result.data as any)[field] === 'string') {
              (result.data as any).images = [{ url: (result.data as any)[field] }];
              break;
            }
          }
        }
        
        if (!result.data.images) {
          throw new Error('FAL API returned data without images field');
        }
      }

      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error, prompt: input.prompt?.substring(0, 100) }, 'Flux Max text-to-image error');
      throw error;
    }
  }

  /**
   * Kontext [pro] - å¤šå›¾åƒç¼–è¾‘ï¼ˆå®éªŒæ€§ï¼‰
   * Proç‰ˆæœ¬çš„å¤šå›¾åƒå¤„ç†åŠŸèƒ½
   */
  static async editMultiImagePro(input: FluxKontextMultiImageInput): Promise<FluxKontextResult> {
    try {
      // ğŸ”§ æ ¹æ®APIæ–‡æ¡£ï¼Œç§»é™¤ä¸æ”¯æŒçš„aspect_ratioå‚æ•°
      const kontextInput = {
        prompt: input.prompt,
        image_urls: input.image_urls,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format
        // âŒ ç§»é™¤ aspect_ratio - Kontext APIä¸æ”¯æŒæ­¤å‚æ•°
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.KONTEXT_PRO_MULTI, prompt: input.prompt?.substring(0, 100), imageCount: input.image_urls?.length }, 'Starting editMultiImagePro');

      const result = await fal.subscribe(FLUX_ENDPOINTS.KONTEXT_PRO_MULTI, {
        input: kontextInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status }, 'Queue update');
        },
      });
      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error, prompt: input.prompt?.substring(0, 100) }, 'Flux Kontext Pro multi-image editing error');
      throw error;
    }
  }

  /**
   * Kontext [pro] - æ–‡æœ¬ç”Ÿæˆå›¾åƒ
   * Proç‰ˆæœ¬çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ
   */
  static async textToImagePro(input: FluxKontextTextToImageInput): Promise<FluxKontextResult> {
    try {
      // ğŸ”§ è½¬æ¢å‚æ•°æ ¼å¼ï¼šæ ‡å‡†FLUXç«¯ç‚¹ä½¿ç”¨image_sizeè€Œä¸æ˜¯aspect_ratio
      const fluxInput = {
        prompt: input.prompt,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        sync_mode: input.sync_mode,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format,
        // ğŸ”§ å°†aspect_ratioè½¬æ¢ä¸ºimage_sizeæ ¼å¼
        image_size: this.convertAspectRatioToImageSize(input.aspect_ratio)
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.FLUX_PRO_TEXT_TO_IMAGE, prompt: input.prompt?.substring(0, 100) }, 'Starting textToImagePro');

      const result = await fal.subscribe(FLUX_ENDPOINTS.FLUX_PRO_TEXT_TO_IMAGE, {
        input: fluxInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status, position: (update as any).queue_position }, 'Queue update');
        },
      });

      fluxLogger.debug({ hasData: !!result.data, imagesCount: result.data?.images?.length || 0 }, 'FAL subscribe result');

      if (!result.data) {
        fluxLogger.error('FAL subscribe returned no data');
        throw new Error('FAL API returned no data - this may indicate a service issue or invalid request');
      }

      // ğŸ” æ£€æŸ¥dataç»“æ„
      if (!result.data.images) {
        fluxLogger.error({ dataKeys: Object.keys(result.data) }, 'FAL subscribe data has no images');

        // ğŸ” å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„å›¾ç‰‡å­—æ®µ
        const possibleFields = ['image', 'output', 'result'];
        for (const field of possibleFields) {
          if ((result.data as any)[field]) {
            fluxLogger.debug({ field }, 'Found potential images in alternate field');
            if (Array.isArray((result.data as any)[field])) {
              (result.data as any).images = (result.data as any)[field];
              break;
            } else if (typeof (result.data as any)[field] === 'string') {
              (result.data as any).images = [{ url: (result.data as any)[field] }];
              break;
            }
          }
        }
        
        if (!result.data.images) {
          throw new Error('FAL API returned data without images field');
        }
      }

      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error, prompt: input.prompt?.substring(0, 100) }, 'Flux Pro text-to-image error');
      throw error;
    }
  }

  /**
   * ä¸Šä¼ æ–‡ä»¶åˆ°å­˜å‚¨æœåŠ¡
   * ğŸ”§ åŒæ—¶ä¸Šä¼ åˆ°FALå’ŒR2å­˜å‚¨ï¼Œä¼˜å…ˆä½¿ç”¨FALå­˜å‚¨é“¾æ¥
   */
  static async uploadFile(file: File): Promise<string> {
    try {
      fluxLogger.info({ fileName: file.name }, 'Starting dual storage upload');

      let falUrl: string | null = null;
      let r2Url: string | null = null;

      try {
        fluxLogger.debug({ fileName: file.name }, 'Uploading to FAL storage (primary)');
        falUrl = await fal.storage.upload(file);
        fluxLogger.info({ falUrl }, 'FAL upload successful');
      } catch (falError) {
        fluxLogger.error({ err: falError }, 'FAL upload failed');
      }
      
      // ğŸ”§ åŒæ—¶å°è¯•ä¸Šä¼ åˆ°R2å­˜å‚¨ï¼ˆå¤‡ä»½å’Œç”¨æˆ·æŸ¥çœ‹ï¼‰
      const isR2Enabled = process.env.NEXT_PUBLIC_ENABLE_R2 === "true";
      const hasR2Config = process.env.R2_ACCOUNT_ID && 
                         process.env.R2_ACCESS_KEY_ID && 
                         process.env.R2_SECRET_ACCESS_KEY &&
                         process.env.R2_BUCKET_NAME;

      if (isR2Enabled && hasR2Config) {
        try {
          fluxLogger.debug({ fileName: file.name }, 'Uploading to R2 storage (backup)');
          r2Url = await r2Storage.uploadFile(file);
          fluxLogger.info({ r2Url }, 'R2 upload successful');
        } catch (r2Error) {
          fluxLogger.warn({ err: r2Error }, 'R2 upload failed (non-critical)');
        }
      } else {
        fluxLogger.debug('R2 storage not configured, skipping R2 upload');
      }
      
      // ğŸ”§ ä¼˜å…ˆè¿”å›FAL URLï¼Œå¦‚æœFALå¤±è´¥åˆ™è¿”å›R2 URL
      if (falUrl) {
        fluxLogger.info({ falUrl }, 'Using FAL URL as primary');
        return falUrl;
      } else if (r2Url) {
        fluxLogger.info({ r2Url }, 'FAL failed, using R2 URL as fallback');
        return r2Url;
      } else {
        throw new Error("Both FAL and R2 storage uploads failed");
      }
      
    } catch (error) {
      fluxLogger.error({ err: error }, 'Dual storage upload failed');
      throw error;
    }
  }

  /**
   * å°†AIç”Ÿæˆçš„å›¾ç‰‡ä¿å­˜åˆ°R2å­˜å‚¨
   * @param imageUrl AIç”Ÿæˆçš„å›¾ç‰‡URL
   * @param prompt ç”Ÿæˆæç¤ºè¯
   */
  static async saveGeneratedImageToR2(imageUrl: string, prompt: string): Promise<string> {
    try {
      // æ£€æŸ¥æ˜¯å¦å¯ç”¨R2å­˜å‚¨
      const isR2Enabled = process.env.NEXT_PUBLIC_ENABLE_R2 === "true";
      const hasR2Config = process.env.R2_ACCOUNT_ID && 
                         process.env.R2_ACCESS_KEY_ID && 
                         process.env.R2_SECRET_ACCESS_KEY &&
                         process.env.R2_BUCKET_NAME;

      if (!isR2Enabled || !hasR2Config) {
        fluxLogger.debug('R2 storage not configured, returning original URL');
        return imageUrl; // å¦‚æœR2æœªé…ç½®ï¼Œè¿”å›åŸå§‹URL
      }

      fluxLogger.debug({ imageUrl }, 'Saving AI generated image to R2');

      // ä½¿ç”¨R2å­˜å‚¨çš„uploadFromUrlæ–¹æ³•
      const result = await r2Storage.uploadFromUrl(imageUrl, prompt);

      fluxLogger.info({ result }, 'AI generated image saved to R2 successfully');
      return result;

    } catch (error) {
      fluxLogger.error({ err: error }, 'Failed to save AI generated image to R2');
      // å¦‚æœä¿å­˜å¤±è´¥ï¼Œè¿”å›åŸå§‹URL
      return imageUrl;
    }
  }

  /**
   * é˜Ÿåˆ—æäº¤ï¼ˆç”¨äºé•¿æ—¶é—´è¿è¡Œçš„è¯·æ±‚ï¼‰
   */
  static async submitToQueue(endpoint: string, input: any): Promise<{ request_id: string }> {
    try {
      const result = await fal.queue.submit(endpoint, {
        input,
        webhookUrl: process.env.NEXT_PUBLIC_SITE_URL + "/api/webhooks/fal"
      });
      return result;
    } catch (error) {
      fluxLogger.error({ err: error }, 'Queue submission error');
      throw error;
    }
  }

  /**
   * æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
   */
  static async checkQueueStatus(endpoint: string, requestId: string): Promise<any> {
    try {
      const status = await fal.queue.status(endpoint, {
        requestId,
        logs: true,
      });
      return status;
    } catch (error) {
      fluxLogger.error({ err: error }, 'Queue status check error');
      throw error;
    }
  }

  /**
   * è·å–é˜Ÿåˆ—ç»“æœ
   */
  static async getQueueResult(endpoint: string, requestId: string): Promise<FluxKontextResult> {
    try {
      const result = await fal.queue.result(endpoint, {
        requestId
      });
      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error }, 'Queue result retrieval error');
      throw error;
    }
  }

  /**
   * FLUX.1 [schnell] - æ–‡æœ¬ç”Ÿæˆå›¾åƒ
   * è¶…å¿«é€Ÿç”Ÿæˆï¼Œ1-4æ­¥å®Œæˆ
   */
  static async textToImageSchnell(input: FluxKontextTextToImageInput): Promise<FluxKontextResult> {
    try {
      // ğŸ”§ è½¬æ¢å‚æ•°æ ¼å¼ï¼šFLUX Schnellç«¯ç‚¹ä½¿ç”¨image_sizeè€Œä¸æ˜¯aspect_ratio
      const schnellInput = {
        prompt: input.prompt,
        seed: input.seed,
        sync_mode: input.sync_mode,
        num_images: input.num_images,
        output_format: input.output_format,
        // ğŸ”§ å°†aspect_ratioè½¬æ¢ä¸ºimage_sizeæ ¼å¼
        image_size: this.convertAspectRatioToImageSize(input.aspect_ratio),
        // ğŸ”§ Schnellæ¨¡å‹ä½¿ç”¨è¾ƒå°‘çš„æ¨ç†æ­¥éª¤
        num_inference_steps: 4
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.FLUX_SCHNELL, prompt: input.prompt?.substring(0, 100) }, 'Starting textToImageSchnell');

      const result = await fal.subscribe(FLUX_ENDPOINTS.FLUX_SCHNELL, {
        input: schnellInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status }, 'Queue update');
        },
      });
      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error }, 'Flux Schnell text-to-image error');
      throw error;
    }
  }

  /**
   * FLUX.1 [dev] - æ–‡æœ¬ç”Ÿæˆå›¾åƒ
   * å¼€å‘æ¨¡å‹ï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
   */
  static async textToImageDev(input: FluxKontextTextToImageInput): Promise<FluxKontextResult> {
    try {
      // ğŸ”§ è½¬æ¢å‚æ•°æ ¼å¼ï¼šFLUX Generalç«¯ç‚¹ä½¿ç”¨image_sizeè€Œä¸æ˜¯aspect_ratio
      const fluxInput = {
        prompt: input.prompt,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        sync_mode: input.sync_mode,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format,
        // ğŸ”§ å°†aspect_ratioè½¬æ¢ä¸ºimage_sizeæ ¼å¼
        image_size: this.convertAspectRatioToImageSize(input.aspect_ratio)
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.FLUX_GENERAL, prompt: input.prompt?.substring(0, 100) }, 'Starting textToImageDev');

      const result = await fal.subscribe(FLUX_ENDPOINTS.FLUX_GENERAL, {
        input: fluxInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status }, 'Queue update');
        },
      });
      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error }, 'Flux Dev text-to-image error');
      throw error;
    }
  }

  /**
   * FLUX Realism - æ–‡æœ¬ç”Ÿæˆå›¾åƒ
   * ç…§ç‰‡çº§çœŸå®æ„Ÿå›¾åƒç”Ÿæˆ
   */
  static async textToImageRealism(input: FluxKontextTextToImageInput): Promise<FluxKontextResult> {
    try {
      // ğŸ”§ ä½¿ç”¨FLUX Generalç«¯ç‚¹å’ŒLoRAå®ç°çœŸå®æ„Ÿé£æ ¼
      const realismInput = {
        prompt: input.prompt,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        sync_mode: input.sync_mode,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format,
        // ğŸ”§ å°†aspect_ratioè½¬æ¢ä¸ºimage_sizeæ ¼å¼
        image_size: this.convertAspectRatioToImageSize(input.aspect_ratio),
        // ğŸ”§ ä½¿ç”¨LoRAå®ç°çœŸå®æ„Ÿé£æ ¼
        loras: [
          {
            path: "https://huggingface.co/XLabs-AI/flux-RealismLora/resolve/main/lora.safetensors",
            scale: 0.8
          }
        ]
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.FLUX_GENERAL, prompt: input.prompt?.substring(0, 100) }, 'Starting textToImageRealism');
      
      const result = await fal.subscribe(FLUX_ENDPOINTS.FLUX_GENERAL, {
        input: realismInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status }, 'Queue update');
        },
      });
      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error }, 'Flux Realism text-to-image error');
      throw error;
    }
  }

  /**
   * FLUX Anime - æ–‡æœ¬ç”Ÿæˆå›¾åƒ
   * åŠ¨æ¼«é£æ ¼å›¾åƒç”Ÿæˆ
   */
  static async textToImageAnime(input: FluxKontextTextToImageInput): Promise<FluxKontextResult> {
    try {
      // ğŸ”§ ä½¿ç”¨FLUX Generalç«¯ç‚¹å’ŒLoRAå®ç°åŠ¨æ¼«é£æ ¼
      const animeInput = {
        prompt: input.prompt,
        seed: input.seed,
        guidance_scale: input.guidance_scale,
        sync_mode: input.sync_mode,
        num_images: input.num_images,
        safety_tolerance: input.safety_tolerance,
        output_format: input.output_format,
        // ğŸ”§ å°†aspect_ratioè½¬æ¢ä¸ºimage_sizeæ ¼å¼
        image_size: this.convertAspectRatioToImageSize(input.aspect_ratio),
        // ğŸ”§ ä½¿ç”¨LoRAå®ç°åŠ¨æ¼«é£æ ¼
        loras: [
          {
            path: "https://huggingface.co/Shakker-Labs/FLUX.1-dev-LoRA-AnimeStyle/resolve/main/FLUX-dev-lora-AnimeStyle.safetensors",
            scale: 0.9
          }
        ]
      };

      fluxLogger.info({ endpoint: FLUX_ENDPOINTS.FLUX_GENERAL, prompt: input.prompt?.substring(0, 100) }, 'Starting textToImageAnime');
      
      const result = await fal.subscribe(FLUX_ENDPOINTS.FLUX_GENERAL, {
        input: animeInput,
        logs: true,
        onQueueUpdate: (update) => {
          fluxLogger.debug({ status: update.status }, 'Queue update');
        },
      });
      return result.data as FluxKontextResult;
    } catch (error) {
      fluxLogger.error({ err: error }, 'Flux Anime text-to-image error');
      throw error;
    }
  }

  /**
   * å°†aspect_ratioè½¬æ¢ä¸ºimage_sizeæ ¼å¼
   */
  static convertAspectRatioToImageSize(aspect_ratio?: string): "square_hd" | "square" | "portrait_4_3" | "portrait_16_9" | "landscape_4_3" | "landscape_16_9" | undefined {
    if (!aspect_ratio) return "landscape_4_3"; // é»˜è®¤å€¼

    // å°†aspect_ratioè½¬æ¢ä¸ºFAL APIæ”¯æŒçš„image_sizeæšä¸¾
    switch (aspect_ratio) {
      case "1:1":
        return "square_hd";
      case "4:3":
        return "landscape_4_3";
      case "3:4":
        return "portrait_4_3";
      case "16:9":
        return "landscape_16_9";
      case "9:16":
        return "portrait_16_9";
      case "21:9":
        return "landscape_16_9"; // 21:9æ˜ å°„åˆ°16:9ï¼Œå› ä¸ºFALä¸æ”¯æŒ21:9
      case "9:21":
        return "portrait_16_9"; // 9:21æ˜ å°„åˆ°9:16ï¼Œå› ä¸ºFALä¸æ”¯æŒ9:21
      case "3:2":
        return "landscape_4_3"; // 3:2æ˜ å°„åˆ°4:3
      case "2:3":
        return "portrait_4_3"; // 2:3æ˜ å°„åˆ°3:4
      default:
        return "landscape_4_3"; // é»˜è®¤æ¨ªå‘4:3
    }
  }
} 